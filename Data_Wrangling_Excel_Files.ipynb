{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data Wrangling Excel Files - Stacey Sandy</center>\n",
    "\n",
    "## Part 1\n",
    "\n",
    "As suggested in Use Case 1 of the <i>From The Expert</i> (FTE), we need to read the other nine stock files and insert their data into the database. While nine files isn't an undue burden to manually read, we are going to look ahead to the time when we may have 100 log files to read and implement this code using the DRY Principle. DRY stands for\n",
    "\n",
    "* Don't \n",
    "* Repeat\n",
    "* Yourself\n",
    "\n",
    "So, while we could create an individual cell to read each stock file, for this assignment, do it in one. I'll give you some help to get started.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "_Reference:_ <br>\n",
    "https://en.wikipedia.org/wiki/Don%27t_repeat_yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of computer science and programming is about identifying and exploiting patterns. In this case, we know there is a pattern to how the files are named, and we know (through inspection) that there is a pattern to the columns of data inside. \n",
    "\n",
    "The file names all start with a year, from 2009 straight to 2019 with no breaks:\n",
    "\n",
    "```\n",
    "2009_aapl_data.xlsx\n",
    "2010_aapl_data.xlsx\n",
    "2011_aapl_data.xlsx\n",
    "2012_aapl_data.xlsx\n",
    "2013_aapl_data.xlsx\n",
    "2014_aapl_data.xlsx\n",
    "2015_aapl_data.xlsx\n",
    "2016_aapl_data.xlsx\n",
    "2017_aapl_data.xlsx\n",
    "2018_aapl_data.xlsx\n",
    "2019_aapl_data.xlsx\n",
    "```\n",
    "\n",
    "Do we know of anything in Python capable of generating a **range** of numbers like that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "#Hint from the instructor in the assignment 2 Jupyter Notebook.\n",
    "for x in range(2009, 2020):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be enough to get you going. Feel free to use code and helper functions from the FTE. I gave you the .ipynb file for a reason :).\n",
    "\n",
    "Remember, \n",
    "\n",
    "* If you ran the FTE code, it will have already read in 2009 and created the database file. \n",
    "* If you start at 2009, depending on the condition above, you may need to handle the table already existing.\n",
    "\n",
    "It is your choice whether or not to use the dataset library. As with many things in life, there are tradeoffs -- some things are easier, some not. \n",
    "\n",
    "**Deliverable:**\n",
    "\n",
    "When you are done, you will have a database table with slightly more than 2500 rows in it. **Show this by doing a query that counts rows in the table.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the type of x.\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, strings do not like numbers (integers) so we must convert them to strings. I also learned the hard way that strings can only be concatenated; therefore, it is best to convert the integers insto strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019\n"
     ]
    }
   ],
   "source": [
    "#This is just a check on the type of x.\n",
    "print(x)\n",
    "#Notice how on the year 2019 only populated from the original for loop because it is no logner in the range for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This applied the variable x to the range values 2009 to 2020.\n",
    "x = range(2009, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n"
     ]
    }
   ],
   "source": [
    "#Here is a simple print of the x range values in a list\n",
    "print(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save the list to the variable year.\n",
    "year = (list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm year type.\n",
    "type(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n"
     ]
    }
   ],
   "source": [
    "#Let's print the values in year variable.\n",
    "print(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>My Assignment deliverables begin here:</b>\n",
    "\n",
    "First let's import all the necessary modules and libraries for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries required for working with xcel spreadsheet files, loading them into a database, and creating a workbook.\n",
    "import dataset\n",
    "from openpyxl import load_workbook\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that all the file names follow the same pattern: YYYY_aapl_data.xlsx where YYYY is a year value.<br>\n",
    "The only thing that changes is the year. :) <br>\n",
    "<p>We will need to create a variable to hold the constant part (_aapl_data.xlsx).</p><br>\n",
    "And also put the database file name (stock_prices.db) into a variable, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here the input name is the xcel spreadsheet file minus the year (YYYY) and the db file name is the stock_prices.db variable.\n",
    "input_name = '_aapl_data.xlsx'\n",
    "db_file = 'stock_prices.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use dataset to create the database (.db) file connection.\n",
    "db = dataset.connect(\"sqlite:///\" + db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, I clearly know the database is empty of tables because I have never done this before. <br>\n",
    "For learning purposes, I am going to ensure no tables return from the database.<br>\n",
    "The following for loop asks for the table names and if the list comes back empty, then this confirms that the database is empty.<br> \n",
    "If the list has something in it, for loop is asked to drop the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a for loop to ensure there are not tables in the database, if so drop the tables.\n",
    "if (len(db.tables) > 0):\n",
    "    for table in db.tables:\n",
    "        db[table].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check if any table exists within the database.\n",
    "db.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create an empty table. We'll create the columns after that from the spreadsheet's first row.\n",
    "# The create_table function returns the table so we automatically have a handle\n",
    "table = db.create_table(\"aapl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From hear on in the assignment, we will open our 2009-2019 data, get the header and create table columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset inserts a dictionary as a row so we will need to loop through each row of the worksheet and construct a dictionary from the cells. The dictionary keys are the column names (which is conveniently stored in the table.columns list) and the values are the cell values.<br>\n",
    "Each worksheet has a values property we can use for our loop's iterable to only return values. This property is just a big block of rows so if we want to slice off the header we have to convert it to something list-like: tuple(sheet.values)[1:]\n",
    "We can build our dictionary from this for loop. <br>\n",
    "<i>Remember we don't have to insert the id column so we will slice it and remove the id.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl_data/2009_aapl_data.xlsx\n",
      "aapl_data/2010_aapl_data.xlsx\n",
      "aapl_data/2011_aapl_data.xlsx\n",
      "aapl_data/2012_aapl_data.xlsx\n",
      "aapl_data/2013_aapl_data.xlsx\n",
      "aapl_data/2014_aapl_data.xlsx\n",
      "aapl_data/2015_aapl_data.xlsx\n",
      "aapl_data/2016_aapl_data.xlsx\n",
      "aapl_data/2017_aapl_data.xlsx\n",
      "aapl_data/2018_aapl_data.xlsx\n",
      "aapl_data/2019_aapl_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "#This is the code to create the file names from the previous input_name. \n",
    "#Then we conduct a nested loop with 2 for loops to load the data.\n",
    "for y in year:\n",
    "    data_file = \"aapl_data/\" + str(y) + input_name\n",
    "    workbook = load_workbook(filename=data_file)\n",
    "    sheet = workbook.active\n",
    "    print(data_file)\n",
    "\n",
    "    #Load datetime from the datetime and date library. Then create for loop function to create dictionary from Dataset rows.\n",
    "    from datetime import datetime,date\n",
    "    keys = table.columns[1:]\n",
    "\n",
    "    for values in list(sheet.values)[1:]:\n",
    "        row = []\n",
    "        row.append(datetime.strptime(values[0],'%Y/%m/%d').date())\n",
    "        row = row + list(values[1:])\n",
    "        d_row = dict(zip(keys,row))\n",
    "        table.insert(d_row)\n",
    "#The final output prints the file names of the excel spreadsheets we loaded into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aapl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check if our table exists within the database.\n",
    "db.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a look at the header\n",
    "header = sheet[1]\n",
    "header[0].value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we need to give the columns a type when we create them, let's create a function to output true or false if our data are listed as the right type for each column. <b>Recall, all of the columns are floating point except for 'date' which is a datetime type.</b><br>\n",
    "<p>NOTE: <br>\n",
    "isdigit() will return True if the string is an integer, but will give False if there is a decimal point. <br>\n",
    "The float() function will throw a ValueError if there are letters in the string.<br>\n",
    "The dates always have '/' in them.<br>\n",
    "Strings will output as Unicode.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "# Note: These have to be tested in the right order. isfloat() reports True for integers.\n",
    "def get_type(value):\n",
    "    if value.isdigit():\n",
    "        return dataset.types.Integer\n",
    "    elif isfloat(value):\n",
    "        return dataset.types.Float\n",
    "    elif '/' in value:\n",
    "        return dataset.types.Date\n",
    "    else:\n",
    "        return dataset.types.Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the columns of the database!<br>\n",
    "We will be using the create_Column function available in the dataset library.<br>\n",
    "The name will be the name of the column in the database, and type corresponds to the Dataset definition from our get_type() function that will return the Dataset type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019/09/04 is <class 'sqlalchemy.sql.sqltypes.Date'>\n",
      "209.1900 is <class 'sqlalchemy.sql.sqltypes.Float'>\n",
      "19216820.0000 is <class 'sqlalchemy.sql.sqltypes.Float'>\n",
      "208.3900 is <class 'sqlalchemy.sql.sqltypes.Float'>\n",
      "209.4800 is <class 'sqlalchemy.sql.sqltypes.Float'>\n",
      "207.3200 is <class 'sqlalchemy.sql.sqltypes.Float'>\n"
     ]
    }
   ],
   "source": [
    "#Let's test the function on row 2.\n",
    "row2 = sheet[2]\n",
    "for cell in row2:\n",
    "    print(f'{cell.value} is {get_type(cell.value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember: header contains the first row cells that are column names\n",
    "# the enumerate function outputs a number to the variable index\n",
    "# index \n",
    "for index, col_name in enumerate(header):\n",
    "    table.create_column(col_name.value, get_type(row2[index].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'date', 'close', 'volume', 'open', 'high', 'low']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's double check our work and output the column with headers.\n",
    "table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In final, we will need to conduct a query to count the number of rows in the worksheet and the number of rows in the database. This should confirm that the data generated accordingly within the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in database: 2516\n"
     ]
    }
   ],
   "source": [
    "#Check the number of rows in database.\n",
    "print(f'Rows in database: {len(table)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Now that you have a working database with a reasonable amount of data in it, do some queries with it and show the data:\n",
    "\n",
    "1. Find all days where the stock closed lower than 25. \n",
    "    * Print a count of how many\n",
    "    * Print the first 5 rows found\n",
    "2. Find all days in 2017 where the stock closed above 35.\n",
    "    * Print a count of how many\n",
    "    * Print the last 5 found.\n",
    "    \n",
    "**Deliverable:**\n",
    "\n",
    "3. Create a new workbook and put each query result on a new worksheet in the workbook. Remember to save it to disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to print all the rows of a worksheet, called print_rows().\n",
    "#Then we will create a new worksheet and query our database.\n",
    "def print_rows():\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the following required libraries\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.chart import BarChart, Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aapl']\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "db = dataset.connect(\"sqlite:///stock_prices.db\")\n",
    "print(db.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('id', 1), ('date', datetime.date(2019, 9, 4)), ('close', 209.19), ('volume', 19216820.0), ('open', 208.39), ('high', 209.48), ('low', 207.32)])\n",
      "OrderedDict([('id', 2), ('date', datetime.date(2019, 9, 3)), ('close', 205.7), ('volume', 20059570.0), ('open', 206.43), ('high', 206.98), ('low', 204.22)])\n",
      "OrderedDict([('id', 3), ('date', datetime.date(2019, 8, 30)), ('close', 208.74), ('volume', 21162560.0), ('open', 210.16), ('high', 210.45), ('low', 207.2)])\n",
      "OrderedDict([('id', 4), ('date', datetime.date(2019, 8, 29)), ('close', 209.01), ('volume', 21007650.0), ('open', 208.5), ('high', 209.32), ('low', 206.655)])\n",
      "OrderedDict([('id', 5), ('date', datetime.date(2019, 8, 28)), ('close', 205.53), ('volume', 15957630.0), ('open', 204.1), ('high', 205.72), ('low', 203.32)])\n",
      "OrderedDict([('id', 6), ('date', datetime.date(2019, 8, 27)), ('close', 204.16), ('volume', 25897340.0), ('open', 207.86), ('high', 208.55), ('low', 203.53)])\n",
      "OrderedDict([('id', 7), ('date', datetime.date(2019, 8, 26)), ('close', 206.49), ('volume', 26066130.0), ('open', 205.86), ('high', 207.19), ('low', 205.0573)])\n",
      "OrderedDict([('id', 8), ('date', datetime.date(2019, 8, 23)), ('close', 202.64), ('volume', 46882840.0), ('open', 209.43), ('high', 212.051), ('low', 201.0)])\n",
      "OrderedDict([('id', 9), ('date', datetime.date(2019, 8, 22)), ('close', 212.46), ('volume', 22267820.0), ('open', 213.19), ('high', 214.435), ('low', 210.75)])\n",
      "OrderedDict([('id', 10), ('date', datetime.date(2019, 8, 21)), ('close', 212.64), ('volume', 21564750.0), ('open', 212.99), ('high', 213.65), ('low', 211.6032)])\n"
     ]
    }
   ],
   "source": [
    "# Just show everything\n",
    "for i, row in enumerate(db['aapl']):\n",
    "    if i < 10:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-04 209.19 19216820.0 208.39 209.48 207.32\n",
      "2019-09-03 205.7 20059570.0 206.43 206.98 204.22\n",
      "2019-08-30 208.74 21162560.0 210.16 210.45 207.2\n",
      "2019-08-29 209.01 21007650.0 208.5 209.32 206.655\n",
      "2019-08-28 205.53 15957630.0 204.1 205.72 203.32\n",
      "2019-08-27 204.16 25897340.0 207.86 208.55 203.53\n",
      "2019-08-26 206.49 26066130.0 205.86 207.19 205.0573\n",
      "2019-08-23 202.64 46882840.0 209.43 212.051 201.0\n",
      "2019-08-22 212.46 22267820.0 213.19 214.435 210.75\n",
      "2019-08-21 212.64 21564750.0 212.99 213.65 211.6032\n"
     ]
    }
   ],
   "source": [
    "# Let's format it a bit\n",
    "for i, row in enumerate(db['aapl']):\n",
    "    if i < 10:\n",
    "        print(f\"{row['date']} {row['close']} {row['volume']} {row['open']} {row['high']} {row['low']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Deliverable 1:\n",
    "    1. Find all days where the stock closed lower than 25. \n",
    "    * Print a count of how many\n",
    "    * Print the first 5 rows found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[417, datetime.date(2009, 9, 14), 24.8171, 80383404.0, 24.4043, 24.8428, 24.3214]\n",
      "[418, datetime.date(2009, 9, 11), 24.5943, 87108026.0, 24.7014, 24.74, 24.41]\n",
      "[419, datetime.date(2009, 9, 10), 24.6514, 122612107.0, 24.58, 24.75, 24.4014]\n",
      "[420, datetime.date(2009, 9, 9), 24.4486, 202624511.0, 24.6828, 24.9243, 24.2428]\n",
      "[421, datetime.date(2009, 9, 8), 24.7043, 78524974.0, 24.7114, 24.7343, 24.5714]\n",
      "[422, datetime.date(2009, 9, 4), 24.33, 93309888.0, 23.8966, 24.3857, 23.87]\n"
     ]
    }
   ],
   "source": [
    "#Create a low_close variable and only return those <= to 25.\n",
    "low_close = db['aapl'].find(close = {'<=': 25})\n",
    "for row in low_close:\n",
    "    vals = [v for k, v in row.items()]\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.date(2009, 9, 14), 24.8171, 80383404.0, 24.4043, 24.8428, 24.3214],\n",
       " [datetime.date(2009, 9, 11), 24.5943, 87108026.0, 24.7014, 24.74, 24.41],\n",
       " [datetime.date(2009, 9, 10), 24.6514, 122612107.0, 24.58, 24.75, 24.4014],\n",
       " [datetime.date(2009, 9, 9), 24.4486, 202624511.0, 24.6828, 24.9243, 24.2428],\n",
       " [datetime.date(2009, 9, 8), 24.7043, 78524974.0, 24.7114, 24.7343, 24.5714]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take the low_close values and input into an excel sheet.\n",
    "low_close = db['aapl'].find(close = {'<=': 25})\n",
    "excel_rows = []\n",
    "\n",
    "# Get the headers\n",
    "# excel_rows.append(db['aapl'].columns[1:])\n",
    "\n",
    "for row in low_close:\n",
    "    vals = [v for k, v in row.items()]\n",
    "    excel_rows.append(vals[1:])\n",
    "\n",
    "#Print the first rows.\n",
    "excel_rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = Workbook() # Create a new workbook\n",
    "sheet = workbook.active # Get the active worksheet\n",
    "\n",
    "header = db['aapl'].columns[1:]\n",
    "# The header row comes from the db as a weird type\n",
    "# so we convert to string\n",
    "header = [str(v) for v in header]\n",
    "sheet.append(header)\n",
    "for row in excel_rows:\n",
    "    sheet.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the excel spreadsheet.\n",
    "lfname = \"lowclose_aapl.xlsx\"\n",
    "\n",
    "workbook.save(filename=lfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Deliverable 2:\n",
    "2. Find all days in 2017 where the stock closed above 35.\n",
    "    * Print a count of how many\n",
    "    * Print the last 5 found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the datatime and parse modules and the utilities required for the next query.\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-29 169.23 25938760.0 170.52 170.59 169.22\n",
      "2017-12-28 171.08 16412270.0 171.0 171.85 170.48\n",
      "2017-12-27 170.6 21477380.0 170.1 170.78 169.71\n",
      "2017-12-26 170.57 33113340.0 170.8 171.47 169.679\n",
      "2017-12-22 175.01 16339690.0 174.68 175.424 174.5\n",
      "2017-12-21 175.01 20848660.0 174.17 176.02 174.1\n",
      "2017-12-20 174.35 23451420.0 174.87 175.42 173.25\n",
      "2017-12-19 174.54 27393660.0 175.03 175.39 174.09\n",
      "2017-12-18 176.42 29385650.0 174.88 177.2 174.86\n",
      "2017-12-15 173.97 40122100.0 173.63 174.17 172.46\n"
     ]
    }
   ],
   "source": [
    "#Use the parser utility to filter for the dates in 2017 and closing higher than 35.\n",
    "theDate = parse(\"2017-12-25\")\n",
    "high_close = db['aapl'].find(close = {'>=': 35}, date = {'between': ['2017-01-01', '2017-12-31']})\n",
    "\n",
    "# date={'between':['Fri, 1 Dec 2000 00:00:00 -0800 (PST)','Fri, 1 Dec 2000 00:30:00 -0800 (PST)']})\n",
    "for i, row in enumerate(high_close):\n",
    "    if i < 10:\n",
    "        print(f\"{row['date']} {row['close']} {row['volume']} {row['open']} {row['high']} {row['low']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.date(2017, 12, 29), 169.23, 25938760.0, 170.52, 170.59, 169.22],\n",
       " [datetime.date(2017, 12, 28), 171.08, 16412270.0, 171.0, 171.85, 170.48],\n",
       " [datetime.date(2017, 12, 27), 170.6, 21477380.0, 170.1, 170.78, 169.71],\n",
       " [datetime.date(2017, 12, 26), 170.57, 33113340.0, 170.8, 171.47, 169.679],\n",
       " [datetime.date(2017, 12, 22), 175.01, 16339690.0, 174.68, 175.424, 174.5]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take the high_close values and input into an excel sheet.\n",
    "high_close = db['aapl'].find(close = {'>=': 35}, date = {'between': ['2017-01-01', '2017-12-31']})\n",
    "excel_rows = []\n",
    "\n",
    "# Get the headers\n",
    "# excel_rows.append(db['aapl'].columns[1:])\n",
    "\n",
    "for row in high_close:\n",
    "    vals = [v for k, v in row.items()]\n",
    "    excel_rows.append(vals[1:])\n",
    "\n",
    "excel_rows[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = Workbook() # Create a new workbook\n",
    "sheet = workbook.active # Get the active worksheet\n",
    "\n",
    "header = db['aapl'].columns[1:]\n",
    "# The header row comes from the db as a weird type\n",
    "# so we convert to string\n",
    "header = [str(v) for v in header]\n",
    "sheet.append(header)\n",
    "for row in excel_rows:\n",
    "    sheet.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the excel spreadsheet.\n",
    "hfname = \"2017highclose_aapl.xlsx\"\n",
    "\n",
    "workbook.save(filename=hfname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In closing, I learned a lot. Keeping It Simple Stupid (KISS), (is a challenge for this Stupid). Sorry if this assignment proved simple enough to make me over think all my code. At least it's complete and I learned enough to get me going next time.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
